{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertConfig, DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "model_path = 'distilbert-base-uncased'\n",
    "config = DistilBertConfig.from_pretrained(model_path, num_labels=1)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset glue/stsb (download: 784.05 KiB, generated: 1.09 MiB, post-processed: Unknown size, total: 1.86 MiB) to /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d983163cb7294356a5bea0e86658f1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=802872.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ea455f6ee64491871f5c641267c4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95c6ba4371f49af907564272ba7f86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12811d3a50ac4182bca1241e697193ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset glue downloaded and prepared to /root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "stsb_train = load_dataset('glue', 'stsb', split='train')\n",
    "stsb_validation = load_dataset('glue', 'stsb', split='validation')\n",
    "stsb_validation = stsb_validation.shuffle(seed=42)\n",
    "stsb_val = datasets.Dataset.from_dict(stsb_validation[:750])\n",
    "stsb_test = datasets.Dataset.from_dict(stsb_validation[750:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "      <td>2.60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>Severe Gales As Storm Clodagh Hits Britain</td>\n",
       "      <td>Merkel pledges NATO solidarity with Latvia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>Dozens of Egyptians hostages taken by Libyan t...</td>\n",
       "      <td>Egyptian boat crash death toll rises as more b...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>President heading to Bahrain</td>\n",
       "      <td>President Xi: China to continue help to fight ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>China, India vow to further bilateral ties</td>\n",
       "      <td>China Scrambles to Reassure Jittery Stock Traders</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>Putin spokesman: Doping charges appear unfounded</td>\n",
       "      <td>The Latest on Severe Weather: 1 Dead in Texas ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5749 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "0                                A plane is taking off.   \n",
       "1                       A man is playing a large flute.   \n",
       "2         A man is spreading shreded cheese on a pizza.   \n",
       "3                          Three men are playing chess.   \n",
       "4                           A man is playing the cello.   \n",
       "...                                                 ...   \n",
       "5744         Severe Gales As Storm Clodagh Hits Britain   \n",
       "5745  Dozens of Egyptians hostages taken by Libyan t...   \n",
       "5746                       President heading to Bahrain   \n",
       "5747         China, India vow to further bilateral ties   \n",
       "5748   Putin spokesman: Doping charges appear unfounded   \n",
       "\n",
       "                                              sentence2  label   idx  \n",
       "0                           An air plane is taking off.   5.00     0  \n",
       "1                             A man is playing a flute.   3.80     1  \n",
       "2     A man is spreading shredded cheese on an uncoo...   3.80     2  \n",
       "3                            Two men are playing chess.   2.60     3  \n",
       "4                    A man seated is playing the cello.   4.25     4  \n",
       "...                                                 ...    ...   ...  \n",
       "5744         Merkel pledges NATO solidarity with Latvia   0.00  5744  \n",
       "5745  Egyptian boat crash death toll rises as more b...   0.00  5745  \n",
       "5746  President Xi: China to continue help to fight ...   0.00  5746  \n",
       "5747  China Scrambles to Reassure Jittery Stock Traders   0.00  5747  \n",
       "5748  The Latest on Severe Weather: 1 Dead in Texas ...   0.00  5748  \n",
       "\n",
       "[5749 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(stsb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5749, 4), (750, 4), (750, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsb_train.shape, stsb_val.shape, stsb_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c58c17091074fd49160fc887862fe33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff6e6f58c8846149a42770272457732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bd4d7892cb42828524be20e97b5d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "enc_train = stsb_train.map(\n",
    "    lambda e: tokenizer(e['sentence1'], e['sentence2'], padding=True, truncation=True), \n",
    "    batched=True, batch_size=1000)\n",
    "\n",
    "enc_val = stsb_val.map(\n",
    "    lambda e: tokenizer(e['sentence1'], e['sentence2'], padding=True, truncation=True), \n",
    "    batched=True, batch_size=1000)\n",
    "\n",
    "enc_test = stsb_test.map(\n",
    "    lambda e: tokenizer(e['sentence1'], e['sentence2'], padding=True, truncation=True), \n",
    "    batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>idx</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[101, 1037, 4946, 2003, 2635, 2125, 1012, 102,...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1037, 2158, 2003, 2652, 1037, 2312, 8928...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is playing a large flute.</td>\n",
       "      <td>A man is playing a flute.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[101, 1037, 2158, 2003, 9359, 14021, 5596, 209...</td>\n",
       "      <td>3.80</td>\n",
       "      <td>A man is spreading shreded cheese on a pizza.</td>\n",
       "      <td>A man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[101, 2093, 2273, 2024, 2652, 7433, 1012, 102,...</td>\n",
       "      <td>2.60</td>\n",
       "      <td>Three men are playing chess.</td>\n",
       "      <td>Two men are playing chess.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>[101, 1037, 2158, 2003, 2652, 1996, 10145, 101...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>A man is playing the cello.</td>\n",
       "      <td>A man seated is playing the cello.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5744</td>\n",
       "      <td>[101, 5729, 14554, 2015, 2004, 4040, 18856, 13...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Severe Gales As Storm Clodagh Hits Britain</td>\n",
       "      <td>Merkel pledges NATO solidarity with Latvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5745</td>\n",
       "      <td>[101, 9877, 1997, 23437, 19323, 2579, 2011, 19...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Dozens of Egyptians hostages taken by Libyan t...</td>\n",
       "      <td>Egyptian boat crash death toll rises as more b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5746</td>\n",
       "      <td>[101, 2343, 5825, 2000, 15195, 102, 2343, 8418...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>President heading to Bahrain</td>\n",
       "      <td>President Xi: China to continue help to fight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5747</td>\n",
       "      <td>[101, 2859, 1010, 2634, 19076, 2000, 2582, 177...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>China, India vow to further bilateral ties</td>\n",
       "      <td>China Scrambles to Reassure Jittery Stock Traders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>5748</td>\n",
       "      <td>[101, 22072, 14056, 1024, 23799, 5571, 3711, 4...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Putin spokesman: Doping charges appear unfounded</td>\n",
       "      <td>The Latest on Severe Weather: 1 Dead in Texas ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5749 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         attention_mask   idx  \\\n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     0   \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     1   \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     2   \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     3   \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...     4   \n",
       "...                                                 ...   ...   \n",
       "5744  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  5744   \n",
       "5745  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  5745   \n",
       "5746  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  5746   \n",
       "5747  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  5747   \n",
       "5748  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  5748   \n",
       "\n",
       "                                              input_ids  label  \\\n",
       "0     [101, 1037, 4946, 2003, 2635, 2125, 1012, 102,...   5.00   \n",
       "1     [101, 1037, 2158, 2003, 2652, 1037, 2312, 8928...   3.80   \n",
       "2     [101, 1037, 2158, 2003, 9359, 14021, 5596, 209...   3.80   \n",
       "3     [101, 2093, 2273, 2024, 2652, 7433, 1012, 102,...   2.60   \n",
       "4     [101, 1037, 2158, 2003, 2652, 1996, 10145, 101...   4.25   \n",
       "...                                                 ...    ...   \n",
       "5744  [101, 5729, 14554, 2015, 2004, 4040, 18856, 13...   0.00   \n",
       "5745  [101, 9877, 1997, 23437, 19323, 2579, 2011, 19...   0.00   \n",
       "5746  [101, 2343, 5825, 2000, 15195, 102, 2343, 8418...   0.00   \n",
       "5747  [101, 2859, 1010, 2634, 19076, 2000, 2582, 177...   0.00   \n",
       "5748  [101, 22072, 14056, 1024, 23799, 5571, 3711, 4...   0.00   \n",
       "\n",
       "                                              sentence1  \\\n",
       "0                                A plane is taking off.   \n",
       "1                       A man is playing a large flute.   \n",
       "2         A man is spreading shreded cheese on a pizza.   \n",
       "3                          Three men are playing chess.   \n",
       "4                           A man is playing the cello.   \n",
       "...                                                 ...   \n",
       "5744         Severe Gales As Storm Clodagh Hits Britain   \n",
       "5745  Dozens of Egyptians hostages taken by Libyan t...   \n",
       "5746                       President heading to Bahrain   \n",
       "5747         China, India vow to further bilateral ties   \n",
       "5748   Putin spokesman: Doping charges appear unfounded   \n",
       "\n",
       "                                              sentence2  \n",
       "0                           An air plane is taking off.  \n",
       "1                             A man is playing a flute.  \n",
       "2     A man is spreading shredded cheese on an uncoo...  \n",
       "3                            Two men are playing chess.  \n",
       "4                    A man seated is playing the cello.  \n",
       "...                                                 ...  \n",
       "5744         Merkel pledges NATO solidarity with Latvia  \n",
       "5745  Egyptian boat crash death toll rises as more b...  \n",
       "5746  President Xi: China to continue help to fight ...  \n",
       "5747  China Scrambles to Reassure Jittery Stock Traders  \n",
       "5748  The Latest on Severe Weather: 1 Dead in Texas ...  \n",
       "\n",
       "[5749 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(enc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./stsb-model',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = np.squeeze(pred.predictions)\n",
    "    return {\n",
    "        \"MSE\": ((preds - pred.label_ids) ** 2).mean().item(),\n",
    "        \"RMSE\": (np.sqrt(((preds - pred.label_ids) ** 2).mean())).item(),\n",
    "        \"MAE\": (np.abs(preds - pred.label_ids)).mean().item(),\n",
    "        \"Pearson\": pearsonr(preds, pred.label_ids)[0],\n",
    "        \"Spearman's Rank\": spearmanr(preds, pred.label_ids)[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=enc_train,\n",
    "    eval_dataset=enc_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num Epochs = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Instantaneous batch size per device = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Gradient Accumulation steps = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Total optimization steps = 2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madrianmoses\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/adrianmoses/huggingface/runs/1kkuiysm\" target=\"_blank\">./stsb-model</a></strong> to <a href=\"https://wandb.ai/adrianmoses/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "transient": {}
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2157' max='2157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2157/2157 04:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Mse</th>\n",
       "      <th>Rmse</th>\n",
       "      <th>Mae</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Spearman's rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.497300</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>0.698019</td>\n",
       "      <td>0.835476</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.851078</td>\n",
       "      <td>0.848007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.577492</td>\n",
       "      <td>0.759929</td>\n",
       "      <td>0.601091</td>\n",
       "      <td>0.873337</td>\n",
       "      <td>0.868375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.522315</td>\n",
       "      <td>0.522315</td>\n",
       "      <td>0.722714</td>\n",
       "      <td>0.552892</td>\n",
       "      <td>0.873993</td>\n",
       "      <td>0.866944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "display_id": "289a538b4a4b80bf8aeb16bcfd34a4f2"
     },
     "output_type": "display_data",
     "transient": {
      "display_id": "289a538b4a4b80bf8aeb16bcfd34a4f2"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./stsb-model/checkpoint-719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./stsb-model/checkpoint-719/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./stsb-model/checkpoint-719/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./stsb-model/checkpoint-719/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ./stsb-model/checkpoint-719/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./stsb-model/checkpoint-1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./stsb-model/checkpoint-1438/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./stsb-model/checkpoint-1438/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./stsb-model/checkpoint-1438/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ./stsb-model/checkpoint-1438/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./stsb-model/checkpoint-2157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./stsb-model/checkpoint-2157/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./stsb-model/checkpoint-2157/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./stsb-model/checkpoint-2157/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in ./stsb-model/checkpoint-2157/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from ./stsb-model/checkpoint-2157 (score: 0.5223150253295898).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2157, training_loss=0.7411218253229854, metrics={'train_runtime': 256.7816, 'train_samples_per_second': 67.166, 'train_steps_per_second': 8.4, 'total_flos': 522206667215532.0, 'train_loss': 0.7411218253229854, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 5749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='907' max='719' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [719/719 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "display_id": "a4fedaf8daa7ccc2a31aaf1e24116333"
     },
     "output_type": "display_data",
     "transient": {
      "display_id": "a4fedaf8daa7ccc2a31aaf1e24116333"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_MSE</th>\n",
       "      <th>eval_RMSE</th>\n",
       "      <th>eval_MAE</th>\n",
       "      <th>eval_Pearson</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>0.158867</td>\n",
       "      <td>0.158867</td>\n",
       "      <td>0.398581</td>\n",
       "      <td>0.301548</td>\n",
       "      <td>0.963016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>0.522315</td>\n",
       "      <td>0.522315</td>\n",
       "      <td>0.722714</td>\n",
       "      <td>0.552892</td>\n",
       "      <td>0.873993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.502323</td>\n",
       "      <td>0.502323</td>\n",
       "      <td>0.708747</td>\n",
       "      <td>0.549059</td>\n",
       "      <td>0.883875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eval_loss  eval_MSE  eval_RMSE  eval_MAE  eval_Pearson\n",
       "train   0.158867  0.158867   0.398581  0.301548      0.963016\n",
       "val     0.522315  0.522315   0.722714  0.552892      0.873993\n",
       "test    0.502323  0.502323   0.708747  0.549059      0.883875"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = [trainer.evaluate(eval_dataset=data) for data in [enc_train, enc_val, enc_test]]\n",
    "pd.DataFrame(q, index=[\"train\", \"val\", \"test\"]).iloc[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.518992900848389"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model for inference\n",
    "\n",
    "s1, s2 = \"A plane is taking off.\", \"An air plane is taking off.\"\n",
    "encoding = tokenizer(s1, s2, return_tensors='pt', padding=True, truncation=True,\n",
    "    max_length=512)\n",
    "input_ids = encoding['input_ids'].to(device)\n",
    "attention_mask = encoding['attention_mask'].to(device)\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "outputs.logits.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to sentence-pair-regression-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in sentence-pair-regression-model/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in sentence-pair-regression-model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in sentence-pair-regression-model/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in sentence-pair-regression-model/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in sentence-pair-regression-model/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in sentence-pair-regression-model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('sentence-pair-regression-model/tokenizer_config.json',\n",
       " 'sentence-pair-regression-model/special_tokens_map.json',\n",
       " 'sentence-pair-regression-model/vocab.txt',\n",
       " 'sentence-pair-regression-model/added_tokens.json',\n",
       " 'sentence-pair-regression-model/tokenizer.json')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "model_path = \"sentence-pair-regression-model\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
